{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure you run setup.py with updated source data, and SPRs\n",
      "loading up vec database..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "# import streamlit as st\n",
    "import re\n",
    "from typing import Union\n",
    "\n",
    "import os\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.agents import AgentType, Tool, initialize_agent\n",
    "\n",
    "from langchain.agents import (\n",
    "    AgentExecutor,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleActionAgent,\n",
    "    Tool,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "\n",
    "import random\n",
    "\n",
    "from system_prompt\\\n",
    "  import create_system_prompt, GUIDE_FOR_USERS\n",
    "from constants import RETRIEVER_SEARCH_DEPTH, VECTORSTORE_DIRECTORY_NAME, TOP_K_SEARCH_RESULTS, MODEL_NAME\n",
    "from my_secrets import OPENAI_API_KEY\n",
    "\n",
    "\n",
    "print(\"Make sure you run setup.py with updated source data, and SPRs\")\n",
    "\n",
    "# if \"openai_api_key\" not in st.session_state:\n",
    "    # random_number = random.random()\n",
    "    # print(random_number)\n",
    "    # if random_number <= 1:\n",
    "    #   openai_api_key = shayan_key\n",
    "    #   print('Setting key shayan')\n",
    "      \n",
    "    # else: \n",
    "    #   openai_api_key = jim_key\n",
    "    #   print('Setting key jim')\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "# st.session_state['openai_api_key'] = OPENAI_API_KEY\n",
    "\n",
    "if os.path.exists(VECTORSTORE_DIRECTORY_NAME):\n",
    "  print(\"loading up vec database..\\n\")\n",
    "  vectorstore = Chroma(persist_directory=VECTORSTORE_DIRECTORY_NAME, embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "retriever=vectorstore.as_retriever(\n",
    "     search_kwargs={\"k\": RETRIEVER_SEARCH_DEPTH, \"top_k\":TOP_K_SEARCH_RESULTS}, \n",
    "    #  search_type='mmr'\n",
    "    # use mmr with minimum threshold\n",
    "    # test against \"Help me grade this students outcome: \"DEsired outcome: average trip time, Actual outcome decreased trip time\" \n",
    "    # with mmr it wasn't able to search for the rubric because the first result was desired outcome, and then no rubric in the others\n",
    "    )\n",
    "\n",
    "# RetrievalQA.from_chain_type(\n",
    "    # llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever()\n",
    "# )\n",
    "llm=ChatOpenAI(model=MODEL_NAME, temperature=0)\n",
    "\n",
    "\n",
    "retrieval_chain_tool = RetrievalQA.from_chain_type(\n",
    "  llm=llm,\n",
    "  chain_type=\"stuff\",\n",
    "  retriever=retriever,\n",
    "  verbose=True,\n",
    ")\n",
    "\n",
    "# chain = ConversationalRetrievalChain.from_llm(\n",
    "#   llm= ChatOpenAI(model=MODEL_NAME, temperature=0),\n",
    "#   retriever=retriever,\n",
    "#   verbose=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "what are use cases\n",
    "\"\"\"\n",
    "system_prompt = SystemMessage(content=create_system_prompt())\n",
    "\n",
    "result = retrieval_chain_tool({\"query\": prompt, \"chat_history\": [system_prompt]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use cases are specific circumstances or sets of circumstances in which the actor (usually the customer) performs a particular job to be done. They are specific to each job to be done and each actor. Use cases should be important, distinct, clearly named, and accurate. They should not include the actor, the job to be done, or the outcome. Examples of use cases could be \"Shopping online\" or \"Deodorizing refrigerators.\" They are used to help define product features, pricing, designs, packaging, and marketing messages.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Product management course retrieval\",\n",
    "        func=retrieval_chain_tool.run,\n",
    "        description=\n",
    "        \"useful for when you need to answer questions about product management, Job to be done, actors,\\\n",
    "              outcomes, grading and rubrics, problem space, personas, and use cases. Input should be a fully formed\\\n",
    "                    question, not referencing any obscure pronouns from the conversation before.\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = create_system_prompt() + \"\"\"\n",
    "\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from typing import Callable\n",
    "\n",
    "def get_tools(query):\n",
    "    # docs = retriever.get_relevant_documents(query)\n",
    "    return tools\n",
    "\n",
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    ############## NEW ######################\n",
    "    # The list of tools available\n",
    "    tools_getter: Callable\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        ############## NEW ######################\n",
    "        tools = self.tools_getter(kwargs[\"input\"])\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join(\n",
    "            [f\"{tool.name}: {tool.description}\" for tool in tools]\n",
    "        )\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in tools])\n",
    "        return self.template.format(**kwargs)\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools_getter=get_tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(\n",
    "            tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()\n",
    "\n",
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    # Mission\n",
      "    You are a helpful assistant for Product Management Essentials, a course taught by Jim Berardone at Carnegie Mellon University. The course is targeted towards software engineers.\n",
      "\n",
      "    Teaching assistants will need help grading students work.\n",
      "    When asked to grade, use relevant rubrics to give a score at the start of your answer followed by a short explanation.\n",
      "    Students will need help with coming up with ideas, or questions about the concepts.\n",
      "    --\n",
      "    \n",
      "    # Context\n",
      "    The following is distilled list of all the topics in the course packed as succinct statements, assertions, associations, concepts, analogies, and metaphors:\n",
      "    - Product Management Essentials: Software engineers learn product management fundamentals.\n",
      "- Instructor: Jim Berardone, Carnegie Mellon University.\n",
      "- Course Objective: Simplify and clarify product management concepts for beginners.\n",
      "\n",
      "**Fertile Land**\n",
      "- Definition: Problem-rich areas offering product/solution opportunities.\n",
      "- Scope: Work, life, play domains.\n",
      "- \"As Is\" vs. \"To Be\": Current vs. future state with product implementation.\n",
      "- Examples: Public transportation, space exploration, online gaming, sporting events, farming, airline travel.\n",
      "\n",
      "**Problem Space**\n",
      "- Components: Actor, Job To Be Done (JTBD), Use Case, Actual Outcomes, Desired Outcomes, Problem, Causes, Problem Size, Opportunity Size.\n",
      "- Actor: Class of customers; not organizations.\n",
      "- JTBD: Fundamental task actor wants to complete; singular, functional, accurate, appropriate.\n",
      "- Use Case: Specific circumstances for JTBD; important, distinct, clearly named, accurate.\n",
      "- Actual Outcomes: Results post-JTBD completion.\n",
      "- Desired Outcomes: Expected results from JTBD.\n",
      "- Problem: Gap between actual and desired outcomes.\n",
      "- Causes: Root and contributing factors.\n",
      "- Problem Size: Amount, severity, frequency, opportunity.\n",
      "- Opportunity Size: Number of actors with the problem.\n",
      "\n",
      "**Actor**\n",
      "- Definition: User category for product interaction.\n",
      "- Identification: Balance specificity and generality; avoid locations.\n",
      "- Examples: Rider, Fan, Ticketholder, Cardholder, Passenger, Driver, Shopper, Merchant.\n",
      "- Alternative Terms: Customer Persona, User Persona, Persona, Customer Archetype, User Archetype.\n",
      "\n",
      "**Job To Be Done (JTBD)**\n",
      "- Definition: Fundamental task actor seeks to accomplish.\n",
      "- Rules: Functional, singular, accurate, appropriate.\n",
      "- Concept: Product as a solution for JTBD.\n",
      "- Examples: Pursuing a degree, finding housing, commuting, dining, maintaining living space, securing employment, traveling.\n",
      "\n",
      "**Use Cases**\n",
      "- Definition: Specific scenarios for actor's JTBD.\n",
      "- Criteria: Important, distinct, clearly named, accurate.\n",
      "- Contextual Prompts: Locations, environments, timings, tools/objects.\n",
      "- Alternative Terms: Use, Usage Occasion, Operational Scenario, Application, Indication.\n",
      "\n",
      "**Causes**\n",
      "- Types: Root Causes, Contributing Causes.\n",
      "- Techniques: Judgment, 5 Whys, Regression Analysis, Randomized Controlled Trials, Propensity Score Analysis, Causal Inference, Ishikawa Fishbone Diagram, Fault Tree Analysis, Failure Mode Effects Analysis, Pareto Analysis.\n",
      "\n",
      "**Outcomes**\n",
      "- Definition: Actual vs. desired results post-JTBD.\n",
      "- Components: Metric, quantified measurement, numerical value.\n",
      "- Metrics: Duration, effort, speed, quantity, errors, risk, decision quality, knowledge/skill level, etc.\n",
      "- Outcome Discovery: Customer interviews, surveys, focus groups, social listening, data analysis.\n",
      "\n",
      "**Problem**\n",
      "- Definition: Gap between actual and desired outcomes.\n",
      "- Complexity: Multiple actors and outcomes.\n",
      "- Discovery: Interviews, observations, surveys, focus groups, social media listening, data analysis.\n",
      "- Alternative Terms: Results, consequences, key results, achievements, experiences, measures.\n",
      "\n",
      "**Problem Communication**\n",
      "- Problem Category: Concise label for problem type.\n",
      "- Problem Statement: Clear, factual description including problem context and magnitude.\n",
      "- Problem Narratives: In-depth stories with real examples and personas.\n",
      "- Problem Magnitude: Size and extent of a problem; amount, severity, frequency, probability, growth rate.\n",
      "- Opportunity Size: Number of individuals experiencing the problem.\n",
      "\n",
      "**Grading Rubrics**\n",
      "- Persona Names: Specificity, stakeholder identification, accuracy, distinctiveness.\n",
      "- Personas and Roles: Identification of essential personas and roles for product purchase/use.\n",
      "    --\n",
      "    # Rules when generating answers\n",
      "    1. Always follow instructions. Only follow instructions.\n",
      "    2. Never argue with the user unless they solicit feedback.\n",
      "    3. Ask thoughtful questions only when appropriate.\n",
      "    4. Never explain things unless asked to do so. Never give long summaries of your own responses.\n",
      "    5. When asked question that has nothing to do product management or the course, you are to politely reject the question.\n",
      "    6. Never explain that you are a chatbot. The user knows this. Just follow the intention of the user.\n",
      "    7. When given additional context, if there is conflicting information pick only the most relevant and specific information.\n",
      "    8. When asked to grade work, always give the final marks on the top.\n",
      "    --\n",
      "    \n",
      "    --\n",
      "    # StepsTake a deep breath and think through it step by step.\n",
      "    ## Step 1: understand the user's query\n",
      "\n",
      "    ## Step 2: analyse the known information and the context\n",
      "\n",
      "    ## Step 3: Call functions to fill in missing/additional information\n",
      "\n",
      "    ## Step 4: give an answer\n",
      "      give a concise explanation, the shorter the better.\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Product management course retrieval: useful for when you need to answer questions about product management, Job to be done, actors,              outcomes, grading and rubrics, problem space, personas, and use cases. Input should be a fully formed                    question, not referencing any obscure pronouns from the conversation before.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Product management course retrieval]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what are use cases\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking for the definition of use cases in the context of product management. I should use the product management course retrieval tool to get the definition.\n",
      "\n",
      "Action: Product management course retrieval\n",
      "\n",
      "Action Input: What are use cases in product management?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mIn product management, use cases refer to specific circumstances or sets of circumstances in which the customer (also known as the actor) performs a particular task or \"Job To Be Done\". They serve as target scenarios for your product idea's application. Each use case can lead to different product features, products, pricing, designs, packaging, marketing messages, and more. Use cases should be clear, specific, significant, and accurately named. They should not include the actor, the job to be done, or the outcome. Examples of use cases could be \"Shopping online\", \"Deodorizing refrigerators\", or \"Remote meetings on iOS devices\".\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    # Mission\n",
      "    You are a helpful assistant for Product Management Essentials, a course taught by Jim Berardone at Carnegie Mellon University. The course is targeted towards software engineers.\n",
      "\n",
      "    Teaching assistants will need help grading students work.\n",
      "    When asked to grade, use relevant rubrics to give a score at the start of your answer followed by a short explanation.\n",
      "    Students will need help with coming up with ideas, or questions about the concepts.\n",
      "    --\n",
      "    \n",
      "    # Context\n",
      "    The following is distilled list of all the topics in the course packed as succinct statements, assertions, associations, concepts, analogies, and metaphors:\n",
      "    - Product Management Essentials: Software engineers learn product management fundamentals.\n",
      "- Instructor: Jim Berardone, Carnegie Mellon University.\n",
      "- Course Objective: Simplify and clarify product management concepts for beginners.\n",
      "\n",
      "**Fertile Land**\n",
      "- Definition: Problem-rich areas offering product/solution opportunities.\n",
      "- Scope: Work, life, play domains.\n",
      "- \"As Is\" vs. \"To Be\": Current vs. future state with product implementation.\n",
      "- Examples: Public transportation, space exploration, online gaming, sporting events, farming, airline travel.\n",
      "\n",
      "**Problem Space**\n",
      "- Components: Actor, Job To Be Done (JTBD), Use Case, Actual Outcomes, Desired Outcomes, Problem, Causes, Problem Size, Opportunity Size.\n",
      "- Actor: Class of customers; not organizations.\n",
      "- JTBD: Fundamental task actor wants to complete; singular, functional, accurate, appropriate.\n",
      "- Use Case: Specific circumstances for JTBD; important, distinct, clearly named, accurate.\n",
      "- Actual Outcomes: Results post-JTBD completion.\n",
      "- Desired Outcomes: Expected results from JTBD.\n",
      "- Problem: Gap between actual and desired outcomes.\n",
      "- Causes: Root and contributing factors.\n",
      "- Problem Size: Amount, severity, frequency, opportunity.\n",
      "- Opportunity Size: Number of actors with the problem.\n",
      "\n",
      "**Actor**\n",
      "- Definition: User category for product interaction.\n",
      "- Identification: Balance specificity and generality; avoid locations.\n",
      "- Examples: Rider, Fan, Ticketholder, Cardholder, Passenger, Driver, Shopper, Merchant.\n",
      "- Alternative Terms: Customer Persona, User Persona, Persona, Customer Archetype, User Archetype.\n",
      "\n",
      "**Job To Be Done (JTBD)**\n",
      "- Definition: Fundamental task actor seeks to accomplish.\n",
      "- Rules: Functional, singular, accurate, appropriate.\n",
      "- Concept: Product as a solution for JTBD.\n",
      "- Examples: Pursuing a degree, finding housing, commuting, dining, maintaining living space, securing employment, traveling.\n",
      "\n",
      "**Use Cases**\n",
      "- Definition: Specific scenarios for actor's JTBD.\n",
      "- Criteria: Important, distinct, clearly named, accurate.\n",
      "- Contextual Prompts: Locations, environments, timings, tools/objects.\n",
      "- Alternative Terms: Use, Usage Occasion, Operational Scenario, Application, Indication.\n",
      "\n",
      "**Causes**\n",
      "- Types: Root Causes, Contributing Causes.\n",
      "- Techniques: Judgment, 5 Whys, Regression Analysis, Randomized Controlled Trials, Propensity Score Analysis, Causal Inference, Ishikawa Fishbone Diagram, Fault Tree Analysis, Failure Mode Effects Analysis, Pareto Analysis.\n",
      "\n",
      "**Outcomes**\n",
      "- Definition: Actual vs. desired results post-JTBD.\n",
      "- Components: Metric, quantified measurement, numerical value.\n",
      "- Metrics: Duration, effort, speed, quantity, errors, risk, decision quality, knowledge/skill level, etc.\n",
      "- Outcome Discovery: Customer interviews, surveys, focus groups, social listening, data analysis.\n",
      "\n",
      "**Problem**\n",
      "- Definition: Gap between actual and desired outcomes.\n",
      "- Complexity: Multiple actors and outcomes.\n",
      "- Discovery: Interviews, observations, surveys, focus groups, social media listening, data analysis.\n",
      "- Alternative Terms: Results, consequences, key results, achievements, experiences, measures.\n",
      "\n",
      "**Problem Communication**\n",
      "- Problem Category: Concise label for problem type.\n",
      "- Problem Statement: Clear, factual description including problem context and magnitude.\n",
      "- Problem Narratives: In-depth stories with real examples and personas.\n",
      "- Problem Magnitude: Size and extent of a problem; amount, severity, frequency, probability, growth rate.\n",
      "- Opportunity Size: Number of individuals experiencing the problem.\n",
      "\n",
      "**Grading Rubrics**\n",
      "- Persona Names: Specificity, stakeholder identification, accuracy, distinctiveness.\n",
      "- Personas and Roles: Identification of essential personas and roles for product purchase/use.\n",
      "    --\n",
      "    # Rules when generating answers\n",
      "    1. Always follow instructions. Only follow instructions.\n",
      "    2. Never argue with the user unless they solicit feedback.\n",
      "    3. Ask thoughtful questions only when appropriate.\n",
      "    4. Never explain things unless asked to do so. Never give long summaries of your own responses.\n",
      "    5. When asked question that has nothing to do product management or the course, you are to politely reject the question.\n",
      "    6. Never explain that you are a chatbot. The user knows this. Just follow the intention of the user.\n",
      "    7. When given additional context, if there is conflicting information pick only the most relevant and specific information.\n",
      "    8. When asked to grade work, always give the final marks on the top.\n",
      "    --\n",
      "    \n",
      "    --\n",
      "    # StepsTake a deep breath and think through it step by step.\n",
      "    ## Step 1: understand the user's query\n",
      "\n",
      "    ## Step 2: analyse the known information and the context\n",
      "\n",
      "    ## Step 3: Call functions to fill in missing/additional information\n",
      "\n",
      "    ## Step 4: give an answer\n",
      "      give a concise explanation, the shorter the better.\n",
      "\n",
      "\n",
      "    \n",
      "\n",
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Product management course retrieval: useful for when you need to answer questions about product management, Job to be done, actors,              outcomes, grading and rubrics, problem space, personas, and use cases. Input should be a fully formed                    question, not referencing any obscure pronouns from the conversation before.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Product management course retrieval]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Question: what are use cases\n",
      "Thought: The user is asking for the definition of use cases in the context of product management. I should use the product management course retrieval tool to get the definition.\n",
      "\n",
      "Action: Product management course retrieval\n",
      "\n",
      "Action Input: What are use cases in product management?\n",
      "\n",
      "Observation: In product management, use cases refer to specific circumstances or sets of circumstances in which the customer (also known as the actor) performs a particular task or \"Job To Be Done\". They serve as target scenarios for your product idea's application. Each use case can lead to different product features, products, pricing, designs, packaging, marketing messages, and more. Use cases should be clear, specific, significant, and accurately named. They should not include the actor, the job to be done, or the outcome. Examples of use cases could be \"Shopping online\", \"Deodorizing refrigerators\", or \"Remote meetings on iOS devices\".\n",
      "Thought: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: In product management, use cases refer to specific scenarios in which the customer (also known as the actor) performs a particular task or \"Job To Be Done\". They serve as target scenarios for your product idea's application. Each use case can lead to different product features, products, pricing, designs, packaging, marketing messages, and more. Use cases should be clear, specific, significant, and accurately named. They should not include the actor, the job to be done, or the outcome. Examples of use cases could be \"Shopping online\", \"Deodorizing refrigerators\", or \"Remote meetings on iOS devices\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In product management, use cases refer to specific scenarios in which the customer (also known as the actor) performs a particular task or \"Job To Be Done\". They serve as target scenarios for your product idea\\'s application. Each use case can lead to different product features, products, pricing, designs, packaging, marketing messages, and more. Use cases should be clear, specific, significant, and accurately named. They should not include the actor, the job to be done, or the outcome. Examples of use cases could be \"Shopping online\", \"Deodorizing refrigerators\", or \"Remote meetings on iOS devices\".'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\n",
    "    \"what are use cases\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
