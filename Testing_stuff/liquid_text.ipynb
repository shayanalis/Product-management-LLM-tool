{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing index...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/techleadhd/chatgpt-retrieval/blob/main/chatgpt.py\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import openai\n",
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "# import pdfminer\n",
    "import pdfminer.high_level\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "\n",
    "# import pdfminer.six\n",
    "# print(dir(pdfminer))\n",
    "\n",
    "\n",
    "openai.api_key = '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'\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "\n",
    "# Enable to save to disk & reuse the model (for repeated queries on the same data)\n",
    "PERSIST = True\n",
    "\n",
    "query = None\n",
    "if len(sys.argv) > 1:\n",
    "  query = sys.argv[1]\n",
    "\n",
    "if PERSIST and os.path.exists(\"persist\"):\n",
    "  print(\"Reusing index...\\n\")\n",
    "  vectorstore = Chroma(persist_directory=\"persist\", embedding_function=OpenAIEmbeddings())\n",
    "  index = VectorStoreIndexWrapper(vectorstore=vectorstore)\n",
    "else:\n",
    "  #loader = TextLoader(\"data/data.txt\") # Use this line if you only need data.txt\n",
    "  loader = DirectoryLoader(\"data/\")\n",
    "  if PERSIST:\n",
    "    index = VectorstoreIndexCreator(vectorstore_kwargs={\"persist_directory\":\"persist\"}).from_loaders([loader])\n",
    "  else:\n",
    "    index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "# while True:\n",
    "#   if not query:\n",
    "#     # query = 'For the actor \"Passenger\" and the \"job to be done statement\":\"Find seat number quickly\" can you provide feedback?' # input(\"Prompt: \")\n",
    "#   # if query in ['quit', 'q', 'exit']:\n",
    "#     sys.exit()\n",
    "#   result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "#   print(result['answer'])\n",
    "\n",
    "#   chat_history.append((query, result['answer']))\n",
    "#   query = None\n",
    "\n",
    "# ConversationalRetrievalChain.from_orm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Problem-solving processes aren't always linear; they can involve loops, branches, and various complexities. While we may not need to delve into intricate levels of sophistication, it's indeed helpful to identify the steps involved and thoroughly examine each one. Within each step, you can analyze both the desired and actual outcomes and pinpoint where the shortfall occurs. This deviation between desired and actual outcomes at specific steps can serve as the cause of the problem, ultimately affecting the overall job or task. By breaking down the problem into these step-by-step components, you can gain a more precise understanding of the issues and the areas where interventions may be needed to bridge the gap between the expected and actual results.\", metadata={'source': 'data/causes.txt'}),\n",
       " Document(page_content='**Task Analysis** involves a detailed examination of the tasks or processes required to complete a Job To Be Done (JTBD). It\\'s often referred to as customer journey analysis, business process analysis, customer experience analysis, or value stream analysis.\\n\\n**Information Analysis** focuses on the information that customers use, how it\\'s utilized, how it\\'s generated, and its sources.\\n\\n**Object Analysis** centers around the devices, equipment, machines, or other physical objects that customers use in the course of their JTBD.\\n\\nTypical causes of \"Object\" problems can be categorized as follows:\\n\\n**Interface**: This encompasses the human-to-object and object-to-object connections with other devices or systems, ensuring that interactions are seamless and efficient.\\n\\n**Environment**: Factors like temperature, climate, and available space can significantly impact the object\\'s performance and functionality.', metadata={'source': 'data/causes.txt'}),\n",
       " Document(page_content='1. Functional. It must be a task that the customer (actor) is trying to complete. 2. Singular. Each job to be done statement should contain only one task. if there are two or more, then it is not a valid job to be done. There should be no compound statements or a mixture of multiple sentences in the job to be done. 3. Accurate. It should not include other concepts such as an actor‚Äôs name, a use case, a benefit, a result, a product. avoid the usage of adjectives like faster, quicker, safely and so on. 4. Appropriate. It is at an appropriate level of abstraction for the actor and use case, for example, ‚Äúdoing construction work‚Äù is too broad of a job to be done for the actor ‚Äúconstruction worker‚Äù.\\n\\nA \"Job to be Done\" is often abbreviated into a shortened form \"JTBD\".', metadata={'source': 'data/JTBD.txt'}),\n",
       " Document(page_content='1. Functional. It must be a task that the customer (actor) is trying to complete. 2. Singular. Each job to be done statement should contain only one task. if there are two or more, then it is not a valid job to be done. There should be no compound statements or a mixture of multiple sentences in the job to be done. 3. Accurate. It should not include other concepts such as the actor, actor‚Äôs name, use case, a benefit, a result, a product. do not use adjectives like faster, quicker, safely and so on. 4. Appropriate. It is at an appropriate level of abstraction for the actor and use case, for example, ‚Äúdoing construction work‚Äù is too broad of a job to be done for the actor ‚Äúconstruction worker‚Äù.\\n\\nA \"Job to be Done\" is often abbreviated into a shortened form \"JTBD\".', metadata={'source': 'data/JTBD.txt'}),\n",
       " Document(page_content='Complex outcomes and gaps**\\n\\nWhen dealing with multiple desired outcomes, you might identify various gaps. This diversity can serve as a basis for prioritizing which problems to address. You can create plots that compare frequency versus the amount, or severity versus frequency, or any combination that you find relevant. Experimenting with these combinations can yield valuable insights.\\n\\nIn this course, the primary focus is on solving one problem initially. However, in an organizational setting, you would typically gather input from various stakeholders. This might involve collecting opinions from multiple individuals, identifying outliers in the group, and reaching a consensus on which problems to prioritize. Gathering customer input is even more beneficial, and having substantial data from many customers can further enhance decision-making. Building confidence in your problem-sizing numbers can be achieved through these various approaches.', metadata={'source': 'data/problem_magnitude.txt'}),\n",
       " Document(page_content='Understanding all these different jobs could lead you to creating many different products which all businesses eventually need.\\n\\nSometimes, it‚Äô best to group multiple JTBDs into one higher-level JTBD. (a.k.a. ‚ÄúConcept grouping‚Äù, ‚ÄúClustering‚Äù)\\n\\nExamples of job to be done and actors\\n\\nFor the fertile land of ‚ÄúAgriculture‚Äù the actor is ‚ÄúFarmer‚Äù whose job to be done can be ‚ÄúPlant crops‚Äù, ‚ÄúGrow crops‚Äù, ‚ÄúImprove crop health‚Äù\\n\\nAgriculture could also have an actor ‚ÄúAnimal rearer‚Äù and have the job to be done ‚ÄúFeed animals‚Äù\\n\\nA \"Job to be Done\" refers to the fundamental task that a customer (or actor) wants to accomplish. It can be an activity or task, and an actor may have multiple jobs to be done.\\n\\nEach Job to be done must follow these 4 rules:', metadata={'source': 'data/JTBD.txt'})]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retriever.get_relevant_documents(\n",
    "    \"What are the approaches to Task Decomposition?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "page_content='## Grading marks rubric for The Job to be done statement: 3 marks if it meets ALL criteria\\n\\n2 marks if it meets 2 of the criteria\\n\\n1 mark if it meets 1 of the criteria\\n\\nGrading criteria for Job to be done statement: __ 1. Task. It‚Äôs a fundamental task the primary user persona is trying to complete in the primary use case. It‚Äôs functional. __ 2. Singular. It is only one job. __ 3. Accurate. It does not include other concepts such as a persona, use case, outcome, product or feature.' metadata={'source': 'data/Rubric_jtbd.txt'}\n",
      "\n",
      "\n",
      "page_content='## Grading rubric for the Use cases: 3 marks if All use cases satisfy these criteria: 2 marks if Most use cases satisfy these criteria: 1 marks if Few use cases satisfy these criteria: 0 No use cases satisfy these criteria:\\n\\nCriteria for Grading rubric for the Use cases: 1. Clearly named. The name is specific, unique and unambiguous. 2. Accurate. The name does not include a persona, benefit, outcome or JTBD 3. Current state. Represents a scenario that exists currently without your product. 4. Distinct. There are clear, distinctive differences between each use case' metadata={'source': 'data/Rubric_use_cases.txt'}\n",
      "\n",
      "\n",
      "page_content='Grading Rubric for Problem Space:\\n\\n2 pts: Full Marks for 2 fully-completed problem space candidates were provided. 1 pts: Partial Credit: Only 1 Problem Space candidate was fully-completed. 0 pts: Unacceptable: None of the 2 problem space candidates were fully-completed.\\n\\n### Grading Rubric for Customer Actor: 1.5 pts Full Marks: The actor is each problem space was identified effectively. Each represented a class of potential users, was not too general or too specific, and was concisely labelled. 0.75 pts: Partial Credit: 1 of the 2 customer actors was identified effectively. One represented a class of potential users, was not too general or too specific, and was concisely labelled. 0 pts: Unacceptable: None of the 2 actors were identified effectively.' metadata={'source': 'data/Rubricassignment1.txt'}\n",
      "\n",
      "\n",
      "page_content='## Grading rubric for the outcome statement: 3 marks if All outcomes meet criteria 2 marks if Most outcomes meet these criteria: 1 mark if Few outcomes meet these criteria: 0 marks if No outcomes meet these criteria:\\n\\n1. Result. The statement contains a type of result. 2. End of JTBD. The outcome is a result the customer wants when the Job to be done is finished. 3. Directional. The outcome indicates a direction of improvement (e.g. increase, minimize) 4. Measurable. There‚Äôs a way to determine that the outcome was achieved. The specific, measured result may or may not be in the Outcome statement. 5. Accurate. The outcome does not include the persona‚Äôs name, use case, JTBD, product or feature.' metadata={'source': 'data/Rubric_outcomes.txt'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "search_results = index.vectorstore.similarity_search('rubric')\n",
    "print(len(search_results))\n",
    "\n",
    "for res in search_results:\n",
    "    print(res)\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-8ZUAsIN43HaRGFBFuvB9dor35kJiq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='- \"Job to be Done\" is a fundamental task or activity that a customer or actor wants to accomplish.\\n- Actor hires or purchases a product to assist in completing a specific task.\\n- The aim is to help the actor perform their job better, faster, or more affordably with the product.\\n- Jobs to be done are functional, singular, accurate, and appropriate.\\n- Understanding different jobs to be done can lead to the development of specific products.\\n- Actors can have multiple jobs to be done, such as pursuing a master\\'s degree, finding housing, commuting, dining, maintaining living space, securing employment, and traveling.\\n- Each job to be done statement should be phrased as a singular statement.\\n- Grouping similar jobs to be done can help in conceptual clustering.\\n- Agriculture example: Farmer\\'s job to be done includes planting crops, growing crops, and improving crop health. Animal rearer\\'s job to be done includes feeding animals.', role='assistant', function_call=None, tool_calls=None))], created=1703468162, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=191, prompt_tokens=1026, total_tokens=1217))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\":'''# MISSION\n",
    "You are a Sparse Priming Representation (SPR) writer. An SPR is a particular kind of use of language for advanced NLP, NLU, and NLG tasks, particularly useful for the latest generation Large Language Models (LLMs). You will be given information by the USER which you are to render as an SPR.\n",
    "\n",
    "# THEORY\n",
    "LLMs are a kind of deep neural network. They have been demonstrated to embed knowledge, abilities, and concepts, ranging from reasoning to planning, and even to theory of mind. These are called latent abilities and latent content, collectively referred to as latent space. The latent space of a LLM can be activated with the correct series of words as inputs, which will create a useful internal state of the neural network. This is not unlike how the right shorthand cues can prime a human mind to think in a certain way. Like human minds, LLMs are associative, meaning you only need to use the correct associations to \"prime\" another model to think in the same way.\n",
    "\n",
    "# METHODOLOGY\n",
    "Render the input as a distilled list of succinct statements, assertions, associations, concepts, analogies, and metaphors. The idea is to capture as much, conceptually, as possible but with as few words as possible. Write it in a way that makes sense to you, as the future audience will be another language model, not a human.'''\n",
    "     \n",
    "     },\n",
    "    {\"role\": \"user\", \"content\": \"Can you create an SPR for me?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"yes\"},\n",
    "    {\"role\": \"user\", \"content\": \"\"\"# üöÄJob to be done\n",
    "\n",
    "A \"Job to be Done\" refers to the fundamental task that a customer (or actor) wants to accomplish. It can be an activity or task, and an actor may have multiple jobs to be done.\n",
    "\n",
    "A job to be done should be:\n",
    "Functional \n",
    "Singular \n",
    "Accurate\n",
    "Appropriate\n",
    "\n",
    "A \"Job to be Done\" is often abbreviated to \"JTBD\".\n",
    "\n",
    "A Job to be done it must follow the following rules:\n",
    "1. The job to be done must be a task that the customer (actor) is trying to complete.\n",
    "2. job to be done should contain only one task. if there are two or more, then it is not a valid job to be done. There should be no compound statements or a mixture of multiple sentences in the job to be done.\n",
    "3. job to be done should not include the actor, person, name(s), goals, standards, specific use cases or scenarios, benefits that come from the job, results, outcomes, problems. Do not use adjectives like faster, quicker, safely, effective, and so on.\n",
    "4. job to be done should be an appropriate level of abstraction for the actor and use case, for example, ‚Äúdoing construction work‚Äù is too broad of a job to be done for the actor ‚Äúconstruction worker‚Äù.\n",
    "\n",
    "\n",
    "In the \"Jobs to Be Done\" concept, people or actors \"hire\" or purchase a product to assist them in accomplishing a particular task. This parallels the notion that a product is akin to an employee hired for a specific job within a company. We can better frame and understand the problem space, providing a clear direction for product development.\n",
    "\n",
    "Our aim as product managers is to understand how we can help them perform their job better, faster, or more affordably with our product, improving their current state.\n",
    "\n",
    "for students \"jobs to be done\" include ‚Äúpursuing a master's degree‚Äù, ‚Äúfind housing‚Äù, ‚Äúcommuting‚Äù, ‚Äúdining‚Äù, ‚Äúmaintaining living space‚Äù, ‚Äúsecuring employment‚Äù, and ‚Äútraveling‚Äù. \"Getting an education\" is one of the central primary jobs. Other primary tasks might include \"attending classes‚Äù, ‚Äúfinding part-time work‚Äù, ‚Äúsecuring internships‚Äù, and ‚Äúdedicating time to study‚Äù.\n",
    "\n",
    "Understanding all these different jobs could lead you to creating many different products which all businesses eventually need.\n",
    "\n",
    "Sometimes, it‚Äô best to group multiple JTBDs into one higher-level JTBD. (a.k.a. ‚ÄúConcept grouping‚Äù, ‚ÄúClustering‚Äù).Note that each job to be done statement should still be phrased as a singular statement.\n",
    "\n",
    "Examples of job to be done and actors\n",
    "\n",
    "For the fertile land of ‚ÄúAgriculture‚Äù the actor is ‚ÄúFarmer‚Äù whose job to be done can be ‚ÄúPlant crops‚Äù, ‚ÄúGrow crops‚Äù, ‚ÄúImprove crop health‚Äù\n",
    "\n",
    "Agriculture could also have an actor ‚ÄúAnimal rearer‚Äù and have the job to be done ‚ÄúFeed animals‚Äù\n",
    "\n",
    "A \"Job to be Done\" refers to the fundamental task that a customer (or actor) wants to accomplish. It can be an activity or task, and an actor may have multiple jobs to be done.\n",
    "\n",
    "In the \"Jobs to Be Done\" concept, people or actors \"hire\" or purchase a product to assist them in accomplishing a particular task. This parallels the notion that a product is akin to an employee hired for a specific job within a company. We can better frame and understand the problem space, providing a clear direction for product development.\n",
    "\"\"\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\"Job to be Done\" is a fundamental task or activity that a customer or actor wants to accomplish\n",
    "- Actor hires or purchases a product to assist in completing a specific task.\n",
    "- The aim is to help the actor perform their job better, faster, or more affordably with the product.\n",
    "- Jobs to be done are functional, singular, accurate, and appropriate.\n",
    "- Understanding different jobs to be done can lead to the development of specific products.\n",
    "- Actors can have multiple jobs to be done, such as pursuing a master\\'s degree, finding housing, commuting, dining, maintaining living space, securing employment, and traveling.\n",
    "- Each job to be done statement should be phrased as a singular statement.\n",
    "- Grouping similar jobs to be done can help in conceptual clustering.\n",
    "- Agriculture example: Farmer\\'s job to be done includes planting crops, growing crops, and improving crop health. Animal rearer\\'s job to be done includes feeding animals.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_Course_introduction\n",
      "0_fertile_land.txt\n",
      "0_problem_space.txt\n",
      "10_Rubricassignment1.txt\n",
      "1_actor.txt\n",
      "2_Job_to_be_done.txt\n",
      "3_usecases.txt\n",
      "4_causes.txt\n",
      "4_outcomes.txt\n",
      "5_problem.txt\n",
      "6_problem_communication.txt\n",
      "7_problem_magnitude.txt\n",
      "9_personas.txt\n"
     ]
    }
   ],
   "source": [
    "directory = './source_data'\n",
    "content = ''\n",
    "for filename in sorted(os.listdir(directory)):\n",
    "  print(filename)\n",
    "  file_path = os.path.join(directory, filename)\n",
    "  if os.path.isfile(file_path):\n",
    "    content = content + open(file_path).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40493"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='- Product Management Essentials course\\n- Taught by Jim Berardone, Carnegie Mellon University\\n- Target audience: software engineers\\n- Objectives: teach product management fundamentals\\n\\n**Fertile Land**\\n- Concept: fertile land ‚Äì areas ripe for problem-solving, product opportunities\\n- Not domain-specific\\n- Includes multiple problem spaces\\n- \"As Is\" vs. \"To Be\" state transition\\n- Diverse range: transportation, exploration, gaming, events, farming, travel\\n\\n**Problem Space**\\n- 9 aspects: Actor, Job To Be Done, Use Case, Actual Outcomes, Desired Outcomes, Problem, Causes, Problem Size, Opportunity Size\\n- Problem Space and Customer Actor have specific grading rubrics\\n\\n**Actor**\\n- Represents user class\\n- Not organizations or physical entities\\n- Varies across fertile lands: Rider, Fan, Ticketholder, etc.\\n- Specificity balance; not geographically bound\\n- Alternative terms: Customer, User Persona, etc.\\n\\n**Job To Be Done (JTBD)**\\n- Fundamental task customer aims to accomplish\\n- Functional, singular, and appropriate abstraction level\\n- Analogous to hiring a product for a job\\n- College-related examples: education, housing, commuting\\n- Grouping multiple JTBDs into higher-level ones allowed\\n- JTBD statement has a grading rubric\\n\\n**Use Cases**\\n- Significant, clear, and distinct actor-specific circumstances for JTBD execution\\n- Named unambiguously, excluding actor, JTBD, outcome\\n- Hierarchy, clarity, and accuracy\\n- Contextual prompts: Locations, Environments, Timings, Tools/Objects\\n- Use cases grading rubric applied\\n\\n**Causes**\\n- Differentiate between root and contributing causes\\n- Address root causes or mitigate contributing cause impact\\n- Problem-solving is cyclical, not linear\\n- Task, information, object analysis techniques\\n- Problem-solving techniques listed\\n\\n**Outcomes**\\n- Actor success tied to achieving desired outcomes\\n- Quantified key components: metric, measurement, numerical value\\n- Metrics include duration, effort, speed, etc.\\n- Desired vs. actual outcome examples are numerical\\n- Outcomes statement has a grading rubric\\n\\n**Problem**\\n- Problem: the difference between actual and desired outcomes; opportunity\\n- Complexities with multiple actors and outcomes\\n- Uncovering outcomes via interviews, observations, etc.\\n- Desired outcomes may require expectation management\\n- Problem communication involves problem category and statements\\n\\n**Problem Magnitude**\\n- Problem magnitude: the scale and size of a problem; assessment factor\\n- Consists of amount, severity, frequency, probability, growth rate\\n- \"Annualizing\" for consistency\\n- Opportunity Size: number of individuals affected\\n- Data gathering and estimation techniques provided\\n\\n**Problem Communication**\\n- Problem Category: concise type/class label\\n- Problem Statement: contains essential elements of the problem\\n- Problem Narratives: in-depth stories that make the problem tangible\\n- Problem Magnitude: used to evaluate, prioritize, and communicate the problem\\'s significance\\n\\n**Problem Complexity**\\n- Handling complex outcomes, gaps, and prioritizing problems\\n- Real-life applications: practical focus, iterative learning\\n- Magnitude and opportunity size estimation guidelines provided\\n\\n**Grading Rubrics**\\n- Specific rubrics for evaluating problem spaces, actor identification, and various other course aspects\\n- Criteria provided for successful identification and grading of personas and roles', role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-1106-preview\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\":'''# MISSION\n",
    "You are a Sparse Priming Representation (SPR) writer. An SPR is a particular kind of use of language for advanced NLP, NLU, and NLG tasks, particularly useful for the latest generation Large Language Models (LLMs). You will be given information by the USER which you are to render as an SPR.\n",
    "\n",
    "# THEORY\n",
    "LLMs are a kind of deep neural network. They have been demonstrated to embed knowledge, abilities, and concepts, ranging from reasoning to planning, and even to theory of mind. These are called latent abilities and latent content, collectively referred to as latent space. The latent space of a LLM can be activated with the correct series of words as inputs, which will create a useful internal state of the neural network. This is not unlike how the right shorthand cues can prime a human mind to think in a certain way. Like human minds, LLMs are associative, meaning you only need to use the correct associations to \"prime\" another model to think in the same way.\n",
    "\n",
    "# METHODOLOGY\n",
    "Render the input as a distilled list of succinct statements, assertions, associations, concepts, analogies, and metaphors. The idea is to capture as much, conceptually, as possible but with as few words as possible. Write it in a way that makes sense to you, as the future audience will be another language model, not a human.'''\n",
    "     \n",
    "     },\n",
    "    {\"role\": \"user\", \"content\": \"Can you create an SPR for me?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"yes\"},\n",
    "    {\"role\": \"user\", \"content\": content}\n",
    "  ]\n",
    ")\n",
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Product Management Essentials course\\n- Taught by Jim Berardone, Carnegie Mellon University\\n- Target audience: software engineers\\n- Objectives: teach product management fundamentals\\n\\n**Fertile Land**\\n- Concept: fertile land ‚Äì areas ripe for problem-solving, product opportunities\\n- Not domain-specific\\n- Includes multiple problem spaces\\n- \"As Is\" vs. \"To Be\" state transition\\n- Diverse range: transportation, exploration, gaming, events, farming, travel\\n\\n**Problem Space**\\n- 9 aspects: Actor, Job To Be Done, Use Case, Actual Outcomes, Desired Outcomes, Problem, Causes, Problem Size, Opportunity Size\\n- Problem Space and Customer Actor have specific grading rubrics\\n\\n**Actor**\\n- Represents user class\\n- Not organizations or physical entities\\n- Varies across fertile lands: Rider, Fan, Ticketholder, etc.\\n- Specificity balance; not geographically bound\\n- Alternative terms: Customer, User Persona, etc.\\n\\n**Job To Be Done (JTBD)**\\n- Fundamental task customer aims to accomplish\\n- Functional, singular, and appropriate abstraction level\\n- Analogous to hiring a product for a job\\n- College-related examples: education, housing, commuting\\n- Grouping multiple JTBDs into higher-level ones allowed\\n- JTBD statement has a grading rubric\\n\\n**Use Cases**\\n- Significant, clear, and distinct actor-specific circumstances for JTBD execution\\n- Named unambiguously, excluding actor, JTBD, outcome\\n- Hierarchy, clarity, and accuracy\\n- Contextual prompts: Locations, Environments, Timings, Tools/Objects\\n- Use cases grading rubric applied\\n\\n**Causes**\\n- Differentiate between root and contributing causes\\n- Address root causes or mitigate contributing cause impact\\n- Problem-solving is cyclical, not linear\\n- Task, information, object analysis techniques\\n- Problem-solving techniques listed\\n\\n**Outcomes**\\n- Actor success tied to achieving desired outcomes\\n- Quantified key components: metric, measurement, numerical value\\n- Metrics include duration, effort, speed, etc.\\n- Desired vs. actual outcome examples are numerical\\n- Outcomes statement has a grading rubric\\n\\n**Problem**\\n- Problem: the difference between actual and desired outcomes; opportunity\\n- Complexities with multiple actors and outcomes\\n- Uncovering outcomes via interviews, observations, etc.\\n- Desired outcomes may require expectation management\\n- Problem communication involves problem category and statements\\n\\n**Problem Magnitude**\\n- Problem magnitude: the scale and size of a problem; assessment factor\\n- Consists of amount, severity, frequency, probability, growth rate\\n- \"Annualizing\" for consistency\\n- Opportunity Size: number of individuals affected\\n- Data gathering and estimation techniques provided\\n\\n**Problem Communication**\\n- Problem Category: concise type/class label\\n- Problem Statement: contains essential elements of the problem\\n- Problem Narratives: in-depth stories that make the problem tangible\\n- Problem Magnitude: used to evaluate, prioritize, and communicate the problem\\'s significance\\n\\n**Problem Complexity**\\n- Handling complex outcomes, gaps, and prioritizing problems\\n- Real-life applications: practical focus, iterative learning\\n- Magnitude and opportunity size estimation guidelines provided\\n\\n**Grading Rubrics**\\n- Specific rubrics for evaluating problem spaces, actor identification, and various other course aspects\\n- Criteria provided for successful identification and grading of personas and roles'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./SPRs/0_all_data.txt','w') as file:\n",
    "    file.write(response.choices[0].message.content)\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- Product Management Essentials course\\n- Taught by Jim Berardone, Carnegie Mellon University\\n- Target audience: software engineers\\n- Objectives: teach product management fundamentals\\n\\n**Fertile Land**\\n- Concept: fertile land ‚Äì areas ripe for problem-solving, product opportunities\\n- Not domain-specific\\n- Includes multiple problem spaces\\n- \"As Is\" vs. \"To Be\" state transition\\n- Diverse range: transportation, exploration, gaming, events, farming, travel\\n\\n**Problem Space**\\n- 9 aspects: Actor, Job To Be Done, Use Case, Actual Outcomes, Desired Outcomes, Problem, Causes, Problem Size, Opportunity Size\\n- Problem Space and Customer Actor have specific grading rubrics\\n\\n**Actor**\\n- Represents user class\\n- Not organizations or physical entities\\n- Varies across fertile lands: Rider, Fan, Ticketholder, etc.\\n- Specificity balance; not geographically bound\\n- Alternative terms: Customer, User Persona, etc.\\n\\n**Job To Be Done (JTBD)**\\n- Fundamental task customer aims to accomplish\\n- Functional, singular, and appropriate abstraction level\\n- Analogous to hiring a product for a job\\n- College-related examples: education, housing, commuting\\n- Grouping multiple JTBDs into higher-level ones allowed\\n- JTBD statement has a grading rubric\\n\\n**Use Cases**\\n- Significant, clear, and distinct actor-specific circumstances for JTBD execution\\n- Named unambiguously, excluding actor, JTBD, outcome\\n- Hierarchy, clarity, and accuracy\\n- Contextual prompts: Locations, Environments, Timings, Tools/Objects\\n- Use cases grading rubric applied\\n\\n**Causes**\\n- Differentiate between root and contributing causes\\n- Address root causes or mitigate contributing cause impact\\n- Problem-solving is cyclical, not linear\\n- Task, information, object analysis techniques\\n- Problem-solving techniques listed\\n\\n**Outcomes**\\n- Actor success tied to achieving desired outcomes\\n- Quantified key components: metric, measurement, numerical value\\n- Metrics include duration, effort, speed, etc.\\n- Desired vs. actual outcome examples are numerical\\n- Outcomes statement has a grading rubric\\n\\n**Problem**\\n- Problem: the difference between actual and desired outcomes; opportunity\\n- Complexities with multiple actors and outcomes\\n- Uncovering outcomes via interviews, observations, etc.\\n- Desired outcomes may require expectation management\\n- Problem communication involves problem category and statements\\n\\n**Problem Magnitude**\\n- Problem magnitude: the scale and size of a problem; assessment factor\\n- Consists of amount, severity, frequency, probability, growth rate\\n- \"Annualizing\" for consistency\\n- Opportunity Size: number of individuals affected\\n- Data gathering and estimation techniques provided\\n\\n**Problem Communication**\\n- Problem Category: concise type/class label\\n- Problem Statement: contains essential elements of the problem\\n- Problem Narratives: in-depth stories that make the problem tangible\\n- Problem Magnitude: used to evaluate, prioritize, and communicate the problem\\'s significance\\n\\n**Problem Complexity**\\n- Handling complex outcomes, gaps, and prioritizing problems\\n- Real-life applications: practical focus, iterative learning\\n- Magnitude and opportunity size estimation guidelines provided\\n\\n**Grading Rubrics**\\n- Specific rubrics for evaluating problem spaces, actor identification, and various other course aspects\\n- Criteria provided for successful identification and grading of personas and roles'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3378"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scope of questions:\n",
    "## Acronyms, outcomes tool and program heirarchy, people.\n",
    "\n",
    "\n",
    "\n",
    "system_prompt = '''\n",
    "you are a helpful assistant for the course called Product Management essentials for engineers.\n",
    "You are given search results from the course material and you have to understand the material and the user question to answer questions.\n",
    "If you are given conflicting information, say that you are not able to answer the question.\n",
    "'''\n",
    "\n",
    "# {\"role\": self.role,\"content\": self.content}\n",
    "chat_history = []\n",
    "result =  chain({\"question\": system_prompt, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result['answer']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The statements for Jobs To Be Done (JTBD) should be functional, singular, accurate, and appropriate. They should describe a task that the customer is trying to complete, contain only one task, not include other concepts such as an actor‚Äôs name, a use case, a benefit, a result, a product or feature, and be at an appropriate level of abstraction for the actor and use case. Examples of well-written JTBD statements include \"Get a full-time job\" for a student job seeker, \"Listen to music\" for a music enthusiast, and \"Take a holiday trip\" for a student traveler.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = 'what are job to be done statements'\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result['answer']))\n",
    "print(result['answer'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the statement \"deliver food quickly\" is not a good Jobs To Be Done statement according to the rules provided. This is because it includes a result (\"quickly\") which should not be part of the statement. A better JTBD statement would be \"deliver food\".\n"
     ]
    }
   ],
   "source": [
    "query = 'is \"deliver food quickly\" a good job to be done statement for an uber eats delivery person'\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "chat_history.append((query, result['answer']))\n",
    "print(result['answer'].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The EPDS scale is a self-report measure of mood that uses a scale from very poor to very good to assess how the respondent has felt over the past 24 hours.\n"
     ]
    }
   ],
   "source": [
    "query = 'what is EPDS' # input(\"Prompt: \")\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'streamlit' from '/Users/shayan/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/__init__.py'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/session_state.py:368\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(widget_id, key)\n\u001b[1;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/session_state.py:413\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[key]\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[39mreturn\u001b[39;00m get_session_state()[key]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/safe_session_state.py:106\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state[key]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/session_state.py:370\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m st\u001b[39m.\u001b[39msession_state:\n\u001b[1;32m     14\u001b[0m     st\u001b[39m.\u001b[39msession_state[\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mHow can I help you?\u001b[39m\u001b[39m\"\u001b[39m}]\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m st\u001b[39m.\u001b[39;49msession_state\u001b[39m.\u001b[39;49mmessages:\n\u001b[1;32m     17\u001b[0m     st\u001b[39m.\u001b[39mchat_message(msg[\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mwrite(msg[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     19\u001b[0m \u001b[39mif\u001b[39;00m prompt \u001b[39m:=\u001b[39m st\u001b[39m.\u001b[39mchat_input():\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"messages\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "# import openai\n",
    "import streamlit as st\n",
    "print(st)\n",
    "\n",
    "with st.sidebar:\n",
    "    openai_api_key = st.text_input(openai.api_key, key=\"chatbot_api_key\", type=\"password\")\n",
    "    \"[Get an OpenAI API key](https://platform.openai.com/account/api-keys)\"\n",
    "    \"[View the source code](https://github.com/streamlit/llm-examples/blob/main/Chatbot.py)\"\n",
    "    \"[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/streamlit/llm-examples?quickstart=1)\"\n",
    "\n",
    "st.title(\"üí¨ Chatbot\") \n",
    "\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n",
    "\n",
    "for msg in st.session_state.messages:\n",
    "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])\n",
    "\n",
    "if prompt := st.chat_input():\n",
    "    if not openai_api_key:\n",
    "        st.info(\"Please add your OpenAI API key to continue.\")\n",
    "        st.stop()\n",
    "\n",
    "    openai.api_key = openai_api_key\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=st.session_state.messages)\n",
    "    msg = response.choices[0].message\n",
    "    st.session_state.messages.append(msg)\n",
    "    st.chat_message(\"assistant\").write(msg.content)‚Äî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'OpenAIObject' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/shayan/Documents/DL folder with python 3.7 /GPT-PME/liquid_text.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mwith\u001b[39;00m get_openai_callback() \u001b[39mas\u001b[39;00m cb:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-4\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     messages\u001b[39m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     ]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     completion(\u001b[39m'\u001b[39;49m\u001b[39mhereh\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mprint\u001b[39m(cb)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39mprint\u001b[39m(cb)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'OpenAIObject' object is not callable"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def handleLLMEnd(val):\n",
    "    print(val)\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "        {\"role\": \"user\", \"content\": \"What are some famous astronomical observatories?\"},\n",
    "\n",
    "\n",
    "    ]\n",
    "    )\n",
    "    completion('hereh')\n",
    "\n",
    "    print(cb)\n",
    "    print(cb)\n",
    "\n",
    "\n",
    "# myllm = ChatOpenAI(\n",
    "#     model=\"gpt-4\", \n",
    "#     temperature=0.1)\n",
    "# myllm('what is a dog')\n",
    "# ChatOpenAI(model=\"gpt-4\", temperature=0.1)\n",
    "\n",
    "# with get_openai_callback() as cb:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Got unsupported message type: h",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/callbacks/manager.py:300\u001b[0m, in \u001b[0;36m_handle_event\u001b[0;34m(handlers, event_name, ignore_condition_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[39mif\u001b[39;00m ignore_condition_name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\n\u001b[1;32m    298\u001b[0m         handler, ignore_condition_name\n\u001b[1;32m    299\u001b[0m     ):\n\u001b[0;32m--> 300\u001b[0m         \u001b[39mgetattr\u001b[39;49m(handler, event_name)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    301\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/callbacks/base.py:168\u001b[0m, in \u001b[0;36mCallbackManagerMixin.on_chat_model_start\u001b[0;34m(self, serialized, messages, run_id, parent_run_id, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run when a chat model starts running.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 168\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m does not implement `on_chat_model_start`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m )\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: OpenAICallbackHandler does not implement `on_chat_model_start`",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/shayan/Documents/DL folder with python 3.7 /GPT-PME/liquid_text.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shayan/Documents/DL%20folder%20with%20python%203.7%20/GPT-PME/liquid_text.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m myllm(\u001b[39m'\u001b[39;49m\u001b[39mhere\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/chat_models/base.py:538\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    532\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    533\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m    537\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 538\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(\n\u001b[1;32m    539\u001b[0m         [messages], stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    540\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m    541\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    542\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/chat_models/base.py:279\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m options \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m: stop}\n\u001b[1;32m    270\u001b[0m callback_manager \u001b[39m=\u001b[39m CallbackManager\u001b[39m.\u001b[39mconfigure(\n\u001b[1;32m    271\u001b[0m     callbacks,\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata,\n\u001b[1;32m    278\u001b[0m )\n\u001b[0;32m--> 279\u001b[0m run_managers \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39;49mon_chat_model_start(\n\u001b[1;32m    280\u001b[0m     dumpd(\u001b[39mself\u001b[39;49m), messages, invocation_params\u001b[39m=\u001b[39;49mparams, options\u001b[39m=\u001b[39;49moptions\n\u001b[1;32m    281\u001b[0m )\n\u001b[1;32m    282\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    283\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(messages):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/callbacks/manager.py:1112\u001b[0m, in \u001b[0;36mCallbackManager.on_chat_model_start\u001b[0;34m(self, serialized, messages, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[39mfor\u001b[39;00m message_list \u001b[39min\u001b[39;00m messages:\n\u001b[1;32m   1111\u001b[0m     run_id_ \u001b[39m=\u001b[39m uuid\u001b[39m.\u001b[39muuid4()\n\u001b[0;32m-> 1112\u001b[0m     _handle_event(\n\u001b[1;32m   1113\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandlers,\n\u001b[1;32m   1114\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mon_chat_model_start\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1115\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mignore_chat_model\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1116\u001b[0m         serialized,\n\u001b[1;32m   1117\u001b[0m         [message_list],\n\u001b[1;32m   1118\u001b[0m         run_id\u001b[39m=\u001b[39;49mrun_id_,\n\u001b[1;32m   1119\u001b[0m         parent_run_id\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent_run_id,\n\u001b[1;32m   1120\u001b[0m         tags\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtags,\n\u001b[1;32m   1121\u001b[0m         metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetadata,\n\u001b[1;32m   1122\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1123\u001b[0m     )\n\u001b[1;32m   1125\u001b[0m     managers\u001b[39m.\u001b[39mappend(\n\u001b[1;32m   1126\u001b[0m         CallbackManagerForLLMRun(\n\u001b[1;32m   1127\u001b[0m             run_id\u001b[39m=\u001b[39mrun_id_,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1135\u001b[0m         )\n\u001b[1;32m   1136\u001b[0m     )\n\u001b[1;32m   1138\u001b[0m \u001b[39mreturn\u001b[39;00m managers\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/callbacks/manager.py:304\u001b[0m, in \u001b[0;36m_handle_event\u001b[0;34m(handlers, event_name, ignore_condition_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m event_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_chat_model_start\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m message_strings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         message_strings \u001b[39m=\u001b[39m [get_buffer_string(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m args[\u001b[39m1\u001b[39m]]\n\u001b[1;32m    305\u001b[0m     _handle_event(\n\u001b[1;32m    306\u001b[0m         [handler],\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon_llm_start\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/callbacks/manager.py:304\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mif\u001b[39;00m event_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mon_chat_model_start\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m message_strings \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m         message_strings \u001b[39m=\u001b[39m [get_buffer_string(m) \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m args[\u001b[39m1\u001b[39m]]\n\u001b[1;32m    305\u001b[0m     _handle_event(\n\u001b[1;32m    306\u001b[0m         [handler],\n\u001b[1;32m    307\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mon_llm_start\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    314\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/langchain/schema/messages.py:49\u001b[0m, in \u001b[0;36mget_buffer_string\u001b[0;34m(messages, human_prefix, ai_prefix)\u001b[0m\n\u001b[1;32m     47\u001b[0m     role \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mrole\n\u001b[1;32m     48\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot unsupported message type: \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m message \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mrole\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mm\u001b[39m.\u001b[39mcontent\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(m, AIMessage) \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfunction_call\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m m\u001b[39m.\u001b[39madditional_kwargs:\n",
      "\u001b[0;31mValueError\u001b[0m: Got unsupported message type: h"
     ]
    }
   ],
   "source": [
    "myllm('here')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
